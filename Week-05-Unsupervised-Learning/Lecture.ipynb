{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68f81be7-a9c8-4794-98d9-70e4de489d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b5233-8467-4b8c-8aac-79c7c253fa20",
   "metadata": {},
   "source": [
    "# The Iris Dataset\n",
    "\n",
    "Here are some pictures of the iris subspecies that we will be working with!\n",
    "\n",
    "### Iris Setosa\n",
    "![alt text](images/irissetosa2.jpg \"setosa\")\n",
    "### Iris Versicolor\n",
    "![alt text](images/versicolor.jpg \"versicolor\")\n",
    "### Iris Virginica\n",
    "![alt text](images/virginica.jpg \"virginica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27536cea-f656-4757-b6b3-b3b9b5873a15",
   "metadata": {},
   "source": [
    "## About the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb2dbd-ed34-491c-b735-fefc2437fa20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  in sklearn datasets, the data is stored in 'data'.  the columns are stored in 'feature_names'\n",
    "iris = sklearn.datasets.load_iris()\n",
    "iris_df=pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2a51995-9044-44d5-9de6-5018f1d59512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  We will add labels for later to see how well our labeling goes\n",
    "iris_labeled_df = iris_df.copy(deep=True)\n",
    "iris_labeled_df['species_index'] = iris['target']\n",
    "#  'target'  contains the coded species label (0,1,2).  The lookup is in 'target names'.\n",
    "iris_names = iris['target_names']\n",
    "# we convert to a dict to add the labels to iris_labeled_df\n",
    "iris_name_dict = dict(zip(range(4), iris_names ))\n",
    "iris_labeled_df['species'] = iris_labeled_df['species_index'].map(iris_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74f211-5cde-4aad-a398-a70763b302a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  We can use pairplot to plot scatterplots of everything with everything else.  We put hisograms on the diagonal\n",
    "cols = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)']\n",
    "sns.pairplot(iris_labeled_df, vars=cols,  hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9dd5e-99d1-489c-a67f-301bcf817971",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4faf749c-ae53-471b-860a-40e3e99fac2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdd270be-f51b-4ee6-980b-f335fa947eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84ba8528-274a-4430-b979-22d355454ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_df['labels'] = kmeans.fit_predict(iris_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27e4d5-5e88-4a64-806b-23340f9c982a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928ef2f-0cf1-4cd0-86b6-fc6de2cce673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)']\n",
    "sns.pairplot(iris_df, vars=cols,  hue='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bd1ec-bbee-493c-8ba3-d81d51e6cc07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accuracy and Confusion\n",
    "\n",
    "There are a number of accuracy metrics we can use when we have the \"correct\"  answer to compare to.  In this case, we can compare the species to see how often it gets the correct answer.  The *accuracy* is the ratio of correct assigments to the number of total assignments.  The \"confusion matrix\" is a $N\\times N$ matrix that displays the number of predictions in eatch categorical value by the number of given values.\n",
    "\n",
    "As a check, the accuracy is the trace (sum of the diagonal values) divided by the total number of cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8d43ca4-3195-4eb4-ac7e-86dbc61cc6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373735a-22a4-4e9c-826b-99f243511265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(iris_df.labels, iris_labeled_df['species_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50549723-32cb-49d7-814a-47f26f934b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  K-means doesn't know how to associate its labels with the orig ones.  We can fix that:\n",
    "map_cluster_dict = dict(zip((0,1,2), (1,0,2) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32328e4c-1345-419c-9fa7-baf09793590b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Better!\n",
    "conf = confusion_matrix(iris_df.labels.map(map_cluster_dict), iris_labeled_df['species_index'])\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d5b75-9dfe-4504-afc5-9c82a9a5c692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(iris_df.labels.map(map_cluster_dict), iris_labeled_df['species_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5b7fa-60f8-420a-932d-0a60a7b172b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note that this is the same as:\n",
    "np.trace(conf)/np.sum(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd55ae-cc81-423f-af8e-a04984dae777",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55a02606-c3dd-4031-a188-34d58c12b942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1a5f158-9fe2-4e11-975a-0744820036d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f6b38-1e3b-498a-8f8d-be72d21ecb31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# courtosy sklearn.org\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "\n",
    "model = model.fit(X)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode='level', p=3)\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis).')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c456c858-f0ef-46ba-92fc-9aebc760703c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newmodel = AgglomerativeClustering(n_clusters=3)\n",
    "iris_df['heirarchical_labels'] = newmodel.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25811372-99b0-4368-b067-8824725d9d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)']\n",
    "sns.pairplot(iris_df, vars=cols, hue='heirarchical_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27df41-ff8c-45f1-ad59-9341bc3e8552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(iris_df.heirarchical_labels, iris_labeled_df['species_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc11aa3-ecd3-449b-9fbe-12828d4ce0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# again, we shuffle since our algorithm is \"untrained\"\n",
    "# performance is similar\n",
    "h_map_cluster_dict = dict(zip((1, 0, 2), (0, 1, 2) ))\n",
    "confusion_matrix(iris_df.heirarchical_labels.map(h_map_cluster_dict), iris_labeled_df['species_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6b050-aacc-491a-8dd2-1299f49f45ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(iris_df.heirarchical_labels.map(h_map_cluster_dict), iris_labeled_df['species_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27fbe1-b4fd-4bfb-9406-0c0fce3cde26",
   "metadata": {},
   "source": [
    "## DBSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8301c-3363-456f-8a7a-4956132080d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN().fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd4e44-8027-42f9-b1c2-ea2e5e4922e5",
   "metadata": {},
   "source": [
    "DBSCAN  doesn't do a great job, since the metrics of two of the species are spatially similar.  So, it finds 2 clusters rather than 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb8b2dd-06ca-41ea-be6a-6bdf8c502422",
   "metadata": {},
   "source": [
    "# Market Analysis with APRIORI:  Coffee Shop Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f695945e-2c8b-466d-bfce-1d5f60c335f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install mlxtend\n",
    "# %pip install networkx\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from mlxtend.frequent_patterns import apriori, association_rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e046bf4-b9ed-4651-8691-6f1236042c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Coffe Shop Sales.xlsx - MBA_Master.csv')\n",
    "\n",
    "# Show the first 10 data points.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a820e-843e-4b8d-9d1c-55e7acf9f3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot = df.pivot_table(index='transaction_number', columns='item', values='amount', aggfunc='sum').fillna(0)\n",
    "\n",
    "# Show the size of the pivoted table.\n",
    "print('Table size: %d rows \\u00d7 %d columns' % df_pivot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec8043-b42f-4695-8aa2-de733039d0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show what the top transactions with the highest amounts look like transposed.\n",
    "def is_within_threshold(value):\n",
    "    return 4 < value\n",
    "\n",
    "df_pivot[df_pivot.select_dtypes(np.number)\n",
    "                 .apply(is_within_threshold, axis=1)\n",
    "                 .any(axis=1)] \\\n",
    "        .T \\\n",
    "        .style \\\n",
    "        .background_gradient(axis=None) \\\n",
    "        .format('{:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a1388-d3eb-49d2-a583-912f71028180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(value):        # You get a False if the value is not greater than 0, which becomes a 0;\n",
    "    return int(0 < value) # you get a True if the value is greater than 0, which becomes a 1.\n",
    "\n",
    "df_pivot = df_pivot.map(encode)\n",
    "\n",
    "# Show what the first 10 look like transposed.\n",
    "def determine_style(condition):                                      # The condition is an array of True or False (from previous encoding step)\n",
    "    return np.where(condition, 'background: navy; color: white', '') # If True, the background color is defined (navy/white); if False, it is not defined.\n",
    "\n",
    "df_pivot.head(10) \\\n",
    "        .T \\\n",
    "        .style \\\n",
    "        .apply(determine_style, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005e410-5c39-47f3-b035-0c31bd217d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our minimum support\n",
    "support = 0.01 \n",
    "frequent_items = apriori(df_pivot, min_support=support, use_colnames=True)\n",
    "frequent_items.sort_values('support', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7a95b-3979-4a65-8a18-cb5792c30658",
   "metadata": {},
   "source": [
    "\"Lift\" is the ratio of the target reponse given the antecedent relative to no condition. In conditional probability speak this is:\n",
    "$$\n",
    "L = \\frac{P_{A|B}}{P_B}\n",
    "$$\n",
    "High lift suggests that the products tend to purchased together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8efc4b-b558-4179-b4a0-474938d535c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = 'lift'\n",
    "min_treshold = 1\n",
    "\n",
    "rules = association_rules(frequent_items, metric=metric, min_threshold=min_treshold)[['antecedents','consequents','support','confidence','lift']]\n",
    "rules.reset_index(drop=True).sort_values('confidence', ascending=False, inplace = True)\n",
    "\n",
    "# Show the metrics.\n",
    "rules.sort_values(['antecedents', 'consequents']) \\\n",
    "     .set_index(['antecedents', 'consequents']) \\\n",
    "     .style \\\n",
    "     .set_table_styles([{'selector': 'th.row_heading', 'props': [('vertical-align', 'text-top')]}]) \\\n",
    "     .background_gradient(axis=0) \\\n",
    "     .format_index(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cf1c3-6046-4aba-9c21-186242b9d570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we build a network from the association rule data\n",
    "import networkx as nx\n",
    "\n",
    "from_nodes = rules.antecedents.apply(', '.join)\n",
    "to_nodes = rules.consequents.apply(', '.join)\n",
    "cxns = zip(from_nodes, to_nodes)\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "G.add_edges_from(cxns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72fe96-6007-4534-8db4-593f3be00618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8, 8))\n",
    "nx.draw_networkx(G, arrows=True, node_size=1000, font_size=10, node_color='tab:green', font_color='blue', connectionstyle='arc3, rad=0.1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee46076-2b1f-45b7-80dc-c2477c7f791f",
   "metadata": {},
   "source": [
    "Here, we see that the arrows flow both ways.  This shouldn't be suprising since the data contains purchases that happen at the same time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2354f1e-ef04-4081-baab-5f86145ab46f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules_even = rules.iloc[::2, :].copy() # Keep only even rows.\n",
    "rules_even.antecedents = rules_even.antecedents.apply(', '.join) # Get rid of frozensets.\n",
    "rules_even.consequents = rules_even.consequents.apply(', '.join) # Get rid of frozensets.\n",
    "rules_even['cxns'] = rules_even['antecedents'] + ' \\u27f7 ' + rules_even['consequents']\n",
    "rules_even= rules_even.sort_values('lift', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941bd8e-aa90-4abf-b3e0-c816dc05d777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(rules_even, y='cxns', x='lift').set_title('Coffee Shop Product Lift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5964bd3-f76a-426d-b73f-d2251e288da8",
   "metadata": {},
   "source": [
    "Apparently, the sweet tooth wins out!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb22cf",
   "metadata": {},
   "source": [
    "Let’s make some predictions!\n",
    "\n",
    "If a person is placing an order for certain items, what are the best suggestions for additional items based on the association rules we’ve mined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6bfdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, display_markdown\n",
    "\n",
    "def suggest_product_for(antecedents, limit=5):                  # Given a list of antecedents, predict some consequents up to the limit.\n",
    "    antecedents = frozenset(antecedents)\n",
    "    condition = rules.antecedents.map(antecedents.issuperset)   # The given antecedents must be a superset of the rules' antecedents.\n",
    "    candidates = rules[condition].explode('consequents')        # Explode to expand the tuple/set/list to individual rows.\n",
    "    suggestions = candidates[~candidates.consequents.isin(antecedents)] \\\n",
    "                            .sort_values('lift', ascending=False) \\\n",
    "                            .drop_duplicates('consequents')     # Sort and then remove suggestions which are already among the antecedents and deduplicate.\n",
    "    return suggestions.head(limit)\n",
    "\n",
    "for antecedents in [{'Plain Croisant'},\n",
    "                    {'Decaf Coffee'},\n",
    "                    {'Plain Croisant', 'Decaf Coffee'}]:\n",
    "    display_markdown(f'Suggestions for *{\", \".join(antecedents)}*', raw=True)\n",
    "    display(suggest_product_for(antecedents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
